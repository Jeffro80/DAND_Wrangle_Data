{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cover the following:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three data sources were accessed for this project. An enhanced Twitter archive was provided as a CSV file which was read into a pandas dataframe. An image_predictions file in TSV format was downloaded using the requests library and loaded into a pandas dataframe. Additional data that was absent from the enhanced Twitter archive was accessed using the Twitter API. This involved using the Tweepy library within python to store the data from each tweet in a JSON file. This data was then read into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of steps were performed to assess the quality and tidiness of the data. .info() was performed on each dataframe to examine the types for each column and to look for missing values. .head(), .tail() and .sample() were used on each dataset to get a visual look at the data and how it was structured. This included looking for obvious incorrect data and to understand what sort of data should be present. It also allowed me to view the structure of the tables and assess tidiness.\n",
    "\n",
    "The data files were examined to look for obvious errors and also to check anomalies, such as ratings that did not appear correct (e.g. denominators that were not 10). This analysis showed that some of the ratings collected were not actual ratings (the ratings were the second instance of a '/' in the text column value).\n",
    "\n",
    "Functions such as .value_counts(), .duplicated() and .isnull() were used to assess if retweets were present in the data (unwanted) and to check for duplication of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant data (retweet_count and favorite_count) from extended_data was merged into twitter_archive_enhanced. The four dog stage columns were concatenated into one column and the correct stage extracted from this column, with values with more than one dog present returned as 'mixed'. The image_predictions table was restructured so that each prediction was on its own row. As the image url was not required for analysis, the column was dropped rather than creating a new table to hold the tweet_id and img_url (for the purpose of tidiness).\n",
    "\n",
    "The tweet_id column was converted to a string as the id did not need to have integer calculations performed on it. Retweeted rows were removed by keeping only rows where the retweeted_status_id column was null. The rating_denominator and rating_numerator clolumns were converted to floats before an improved regex was written to extract the ratings values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
